# Лабораторная работа: **Деревья решений и ансамбли**

## Набор данных

1. Выберите любой набор данных для задачи **классификации**.
   - Желательно использовать набор данных с курса **Анализа данных**.
   - Примеры данных: [Kaggle Datasets](https://www.kaggle.com/datasets) или [UCI Repository](https://archive.ics.uci.edu/ml/index.php).
   
2. **Преобразуйте данные в числовой вид** — закодируйте категориальные признаки и выполните нормализацию при необходимости.

3. Разделите данные на **тренировочную** и **тестовую** части.

4. Выберите целевую функцию для оценки модели, например, **accuracy**, **log loss** или **F1-score**.

---

## Алгоритмы

### Реализация алгоритмов:

1. **Дерево принятия решений**:
   - Реализуйте алгоритм построения дерева решений.
   - Алгоритм должен поддерживать **не менее 3 гиперпараметров** для ограничения размера дерева, таких как:
     - Максимальная глубина дерева.
     - Минимальное количество выборок для разбиения узла.
     - Минимальное количество выборок в листе.

2. **Алгоритм бустинга**:
   - Реализуйте алгоритм **градиентного бустинга** ([информация на Wikipedia](https://en.wikipedia.org/wiki/Gradient_boosting)).
   - Используйте ансамбль деревьев решений для повышения качества модели.

3. **Случайный лес**:
   - Реализуйте алгоритм **случайного леса** ([RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)).
   - Ансамблируйте множество деревьев с разными подвыборками признаков для улучшения устойчивости модели.

---

## Задание

### 1. Дерево решений
- Выберите библиотечную реализацию дерева решений, например, [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) из **scikit-learn**.
- **Переберите значения гиперпараметров** для ограничения высоты дерева.
- Постройте **график зависимости высоты дерева** от значений гиперпараметров.

### 2. Оптимизация гиперпараметров
- При помощи **оптимизации гиперпараметров** (рекомендуется [Optuna](https://optuna.org/)) найдите лучшие параметры для:
  - Вашей реализации дерева решений.
  - Библиотечной реализации дерева решений.

- Постройте график зависимости целевой функции ошибки или качества от **высоты дерева** на тренировочном и тестовом множестве для обеих реализаций.

### 3. Бустинг и случайный лес
- **Найдите лучшие гиперпараметры** для вашей и библиотечной реализации алгоритмов **бустинга** и **случайного леса**.
- Постройте **график зависимости** целевой функции ошибки или качества от **числа деревьев** на тренировочном и тестовом множестве для обеих реализаций.

---

## Дополнительные материалы

- Библиотечные реализации:
  - [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html).
  - [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).
  - [GradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html).

- Оптимизация гиперпараметров с [Optuna](https://optuna.org/).
- Теория бустинга на [Wikipedia](https://en.wikipedia.org/wiki/Gradient_boosting).
