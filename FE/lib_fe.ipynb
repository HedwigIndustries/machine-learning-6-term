{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-13T08:09:27.842862Z",
     "start_time": "2024-09-13T08:09:27.634274Z"
    }
   },
   "source": [
    "import typing as tp\n",
    "\n",
    "import pandas as pd"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:09:27.855786Z",
     "start_time": "2024-09-13T08:09:27.843742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('SMS.tsv', delimiter='\\t')\n",
    "df"
   ],
   "id": "453049f731f7ba1e",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:09:27.954205Z",
     "start_time": "2024-09-13T08:09:27.948401Z"
    }
   },
   "cell_type": "code",
   "source": "df.describe()",
   "id": "f02226033af667d8",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:31:06.219930Z",
     "start_time": "2024-09-13T08:31:06.215541Z"
    }
   },
   "cell_type": "code",
   "source": "y = df['class'].map({'ham': 0, 'spam': 1})",
   "id": "1a98d6e04fd2c844",
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:31:06.561844Z",
     "start_time": "2024-09-13T08:31:06.558643Z"
    }
   },
   "cell_type": "code",
   "source": "y, y.shape",
   "id": "fccaa71a897d552a",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:09:28.981202Z",
     "start_time": "2024-09-13T08:09:28.978859Z"
    }
   },
   "cell_type": "code",
   "source": "df[\"text\"][0]",
   "id": "5163f1633c5451a3",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:09:30.084751Z",
     "start_time": "2024-09-13T08:09:29.944383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ],
   "id": "7a73fb77337be4a9",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download()"
   ],
   "id": "e44dc68a84ad8ea1",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "nltk.download('punkt_tab')",
   "id": "f1550f13a5d5300d",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:09:32.715278Z",
     "start_time": "2024-09-13T08:09:32.713162Z"
    }
   },
   "cell_type": "code",
   "source": "import numpy as np",
   "id": "9bb8af7b6a805b01",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:09:32.881694Z",
     "start_time": "2024-09-13T08:09:32.878122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calc_frequency_matrix(df: pd.DataFrame) -> [np.ndarray, list[str]]:\n",
    "    unique_words = set()\n",
    "    tokenized_texts = df['text'].apply(lambda x: word_tokenize(x.lower()))\n",
    "    for text in tokenized_texts:\n",
    "        unique_words.update(text)\n",
    "\n",
    "    unique_words = list(unique_words)\n",
    "    word_index = {word: i for i, word in enumerate(unique_words)}\n",
    "    frequency_matrix = []\n",
    "    for text in tokenized_texts:\n",
    "        word_count = [0] * len(unique_words)\n",
    "        for word in text:\n",
    "            if word in word_index:\n",
    "                word_count[word_index[word]] += 1\n",
    "        frequency_matrix.append(word_count)\n",
    "    return np.array(frequency_matrix), unique_words"
   ],
   "id": "1b3070b243094e36",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:09:35.769157Z",
     "start_time": "2024-09-13T08:09:33.697233Z"
    }
   },
   "cell_type": "code",
   "source": "frequency_matrix, unique_words = calc_frequency_matrix(df)",
   "id": "31cc758c96d2b1cf",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:09:35.776159Z",
     "start_time": "2024-09-13T08:09:35.770343Z"
    }
   },
   "cell_type": "code",
   "source": "print(unique_words, len(unique_words))",
   "id": "db4e17f4290ec70b",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:09:35.779074Z",
     "start_time": "2024-09-13T08:09:35.776901Z"
    }
   },
   "cell_type": "code",
   "source": "frequency_matrix.shape",
   "id": "34b79c26c6451df5",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:09:37.495302Z",
     "start_time": "2024-09-13T08:09:37.492948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_used_words(vector: np.ndarray, unique_words: list[str]) -> list[str]:\n",
    "    non_zero_indices = np.where(vector > 0)[0]\n",
    "    words = [unique_words[i] for i in non_zero_indices]\n",
    "    return words"
   ],
   "id": "c4f43daefeb070b3",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:09:38.256640Z",
     "start_time": "2024-09-13T08:09:38.254723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vector = frequency_matrix[0]\n",
    "used_words = get_used_words(vector, unique_words)"
   ],
   "id": "17edcf9850cae382",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:09:39.890420Z",
     "start_time": "2024-09-13T08:09:39.887244Z"
    }
   },
   "cell_type": "code",
   "source": "used_words",
   "id": "cd41359b27db12b",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:09:42.979459Z",
     "start_time": "2024-09-13T08:09:42.976227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ],
   "id": "d178fc075a29401",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:09:43.848372Z",
     "start_time": "2024-09-13T08:09:43.845009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_accuracy(X: np.ndarray, y: np.ndarray, type: str) -> None:\n",
    "    classifiers: dict[\n",
    "        str,\n",
    "        tp.Union[DecisionTreeClassifier, SVC, KNeighborsClassifier]\n",
    "    ] = {\n",
    "        'Decision Tree': DecisionTreeClassifier(),\n",
    "        'SVM': SVC(),\n",
    "        'KNN': KNeighborsClassifier()\n",
    "    }\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    for name, classifier in classifiers.items():\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        print(\n",
    "            f'{type}:> '\n",
    "            f'Classifier: {name}. '\n",
    "            f'Accuracy: {accuracy_score(y_test, y_pred)}. '\n",
    "        )\n",
    "\n",
    "\n",
    "def print_diff_classifiers(X, y, selected_features, select_method: str) -> None:\n",
    "    print_accuracy(X=X, y=y, type=f\"Before {select_method}\")\n",
    "    X_selected = X[:, selected_features]\n",
    "    print_accuracy(X=X_selected, y=y, type=f\"After {select_method}\")"
   ],
   "id": "d85a4711cfcdb13b",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Filter method:>",
   "id": "150c8bd6fa0015fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from sklearn.feature_selection import SelectKBest, chi2",
   "id": "551d92995468cdef",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "select_kbest = SelectKBest(chi2, k=30)\n",
    "X_new = select_kbest.fit_transform(frequency_matrix, y)\n",
    "selected_features = np.array(unique_words)[select_kbest.get_support()]\n",
    "\n",
    "print(\"Best features by filter KBest:\", selected_features.tolist())"
   ],
   "id": "85277cccfe7bb950",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print_diff_classifiers(frequency_matrix, y, select_kbest.get_support(), select_method=\"SelectKBest\")",
   "id": "78b3902baa2ff68d",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Wrapper method:>",
   "id": "510df51d55a74ed0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:31:45.372637Z",
     "start_time": "2024-09-13T08:31:45.369724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "frequency_matrix = frequency_matrix[:500, :]\n",
    "y = y[:500]"
   ],
   "id": "4d57a8958c455212",
   "execution_count": 31,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:32:10.792646Z",
     "start_time": "2024-09-13T08:31:46.703279Z"
    }
   },
   "cell_type": "code",
   "source": "from sklearn.feature_selection import RFE",
   "id": "8e583ae85180dc1c",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:41:43.402453Z",
     "start_time": "2024-09-13T08:41:18.298659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = DecisionTreeClassifier()\n",
    "rfe = RFE(estimator=model, n_features_to_select=10)\n",
    "rfe = rfe.fit(frequency_matrix, y)\n",
    "rfe.ranking_"
   ],
   "id": "2455523449fd726c",
   "execution_count": 33,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:41:49.757980Z",
     "start_time": "2024-09-13T08:41:49.752155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "important_features = np.array(unique_words)[rfe.support_]\n",
    "print(\"Best features by wrapper RFE:\", important_features.tolist())"
   ],
   "id": "9b311e646ef78f47",
   "execution_count": 35,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:42:13.802826Z",
     "start_time": "2024-09-13T08:42:13.756073Z"
    }
   },
   "cell_type": "code",
   "source": "print_diff_classifiers(frequency_matrix, y, rfe.support_, select_method=\"RFE\")",
   "id": "d9f347378ecf0f05",
   "execution_count": 36,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Embedded method:>",
   "id": "5ca6eb6ab67ac5cc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e645c53a7995d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(frequency_matrix, y)\n",
    "features = decision_tree.feature_importances_\n",
    "tuple_values = [(i, unique_words[i], importance) for i, importance in enumerate(features)]\n",
    "tuple_values = sorted(tuple_values, key=lambda x: x[2], reverse=True)\n",
    "indices, names, _ = zip(*tuple_values)\n",
    "# Печать наиболее важных признаков\n",
    "print(\"Best features by embedded DecisionTreeClassifier:\", names[:30])"
   ],
   "id": "efa17e16ab431532",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print_diff_classifiers(frequency_matrix, y, indices[:30], select_method=\"DecisionTreeClassifier\")",
   "id": "79e8bfb8a28241e",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "list1 = ['stop', 'horo', '#', 'have', 'your', 'text', 'mobile', 'pix', 'or', 'ask', 'a', 'aight', 'call', 'not', 'i', 'me', '!', 'u', 'with', 'extra', 'its', 'later', 'to', 'free', 'for', 'prize', 'quite', 'txt', 'you', 'while']\n",
    "list2 = ['call', 'txt', 'i', 'text', 'me', 'reply', 'http', 'won', 'to', '150p/msg', 'claim', 'you', 'tones', 'reveal', 'ringtone', 'service', '18', 'stop', 'my', 'for', 'now', '..', '150p', 'selection', 'ill', 'chat', 'ask', 'not', ';', 'games']\n",
    "set1 = set(list1)\n",
    "set2 = set(list2)\n",
    "common_elements = set1.intersection(set2)\n",
    "unique_in_list1 = set1.difference(set2)\n",
    "unique_in_list2 = set2.difference(set1)\n",
    "common_elements = list(common_elements)\n",
    "unique_in_list1 = list(unique_in_list1)\n",
    "unique_in_list2 = list(unique_in_list2)\n",
    "print(\"Common elements:\", common_elements)\n",
    "print(\"Unique to list1:\", unique_in_list1)\n",
    "print(\"Unique to list2:\", unique_in_list2)"
   ],
   "id": "1664116539eebb1b",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "292de19bbfeda096",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
