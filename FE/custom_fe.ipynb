{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-13T08:32:51.020243Z",
     "start_time": "2024-09-13T08:32:50.766959Z"
    }
   },
   "source": [
    "import typing as tp\n",
    "\n",
    "import pandas as pd"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:32:51.033528Z",
     "start_time": "2024-09-13T08:32:51.021127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('SMS.tsv', delimiter='\\t')\n",
    "df"
   ],
   "id": "9fc2b9d1f8cfba99",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:32:51.493605Z",
     "start_time": "2024-09-13T08:32:51.487899Z"
    }
   },
   "cell_type": "code",
   "source": "df.describe()",
   "id": "a24a34d751b0320d",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:32:52.139236Z",
     "start_time": "2024-09-13T08:32:52.136385Z"
    }
   },
   "cell_type": "code",
   "source": "y = df['class'].map({'ham': 0, 'spam': 1})",
   "id": "789cdfaa4e6873c",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:32:52.604803Z",
     "start_time": "2024-09-13T08:32:52.601990Z"
    }
   },
   "cell_type": "code",
   "source": "y, y.shape",
   "id": "fd2b4d68036a7600",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:32:53.169332Z",
     "start_time": "2024-09-13T08:32:53.166909Z"
    }
   },
   "cell_type": "code",
   "source": "df[\"text\"][0]",
   "id": "f3e6018036f81bc4",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:32:54.623307Z",
     "start_time": "2024-09-13T08:32:53.908649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ],
   "id": "c11be8b646ff1e9d",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T00:25:11.315799Z",
     "start_time": "2024-09-13T00:25:03.841520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download()"
   ],
   "id": "464d0e3bca67da05",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T00:25:14.657460Z",
     "start_time": "2024-09-13T00:25:14.652631Z"
    }
   },
   "cell_type": "code",
   "source": "nltk.download('punkt_tab')",
   "id": "322c19cd9125e15f",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:32:57.034006Z",
     "start_time": "2024-09-13T08:32:57.031970Z"
    }
   },
   "cell_type": "code",
   "source": "import numpy as np",
   "id": "d63439599315ea09",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:32:57.197690Z",
     "start_time": "2024-09-13T08:32:57.194358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calc_frequency_matrix(df: pd.DataFrame) -> [np.ndarray, list[str]]:\n",
    "    unique_words = set()\n",
    "\n",
    "    tokenized_texts = df['text'].apply(lambda x: word_tokenize(x.lower()))\n",
    "    for text in tokenized_texts:\n",
    "        unique_words.update(text)\n",
    "\n",
    "    unique_words = list(unique_words)\n",
    "    word_index = {word: i for i, word in enumerate(unique_words)}\n",
    "    frequency_matrix = []\n",
    "    for text in tokenized_texts:\n",
    "        word_count = [0] * len(unique_words)\n",
    "        for word in text:\n",
    "            if word in word_index:\n",
    "                word_count[word_index[word]] += 1\n",
    "        frequency_matrix.append(word_count)\n",
    "    return np.array(frequency_matrix), unique_words"
   ],
   "id": "57b8459b7a4a598f",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:32:59.631540Z",
     "start_time": "2024-09-13T08:32:57.566594Z"
    }
   },
   "cell_type": "code",
   "source": "frequency_matrix, unique_words = calc_frequency_matrix(df)",
   "id": "485ffbbc0571101",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:32:59.638572Z",
     "start_time": "2024-09-13T08:32:59.632832Z"
    }
   },
   "cell_type": "code",
   "source": "print(unique_words, len(unique_words))",
   "id": "95f9ea1378ea58ca",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:33:01.303532Z",
     "start_time": "2024-09-13T08:33:01.300787Z"
    }
   },
   "cell_type": "code",
   "source": "frequency_matrix.shape",
   "id": "4125548d76a163df",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:33:02.647686Z",
     "start_time": "2024-09-13T08:33:02.645228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_used_words(vector: np.ndarray, unique_words: list[str]) -> list[str]:\n",
    "    non_zero_indices = np.where(vector > 0)[0]\n",
    "    words = [unique_words[i] for i in non_zero_indices]\n",
    "    return words"
   ],
   "id": "6786ceaf05a45ee4",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:33:02.805205Z",
     "start_time": "2024-09-13T08:33:02.803056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vector = frequency_matrix[0]\n",
    "used_words = get_used_words(vector, unique_words)"
   ],
   "id": "c04395aed3aa033e",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:33:02.944329Z",
     "start_time": "2024-09-13T08:33:02.941892Z"
    }
   },
   "cell_type": "code",
   "source": "used_words",
   "id": "3352f41dd16d0ed1",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:33:05.577558Z",
     "start_time": "2024-09-13T08:33:05.531080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ],
   "id": "5fadb0c0755759a9",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:33:05.675900Z",
     "start_time": "2024-09-13T08:33:05.672935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_accuracy(X: np.ndarray, y: np.ndarray, type: str) -> None:\n",
    "    classifiers: dict[\n",
    "        str,\n",
    "        tp.Union[DecisionTreeClassifier, SVC, KNeighborsClassifier]\n",
    "    ] = {\n",
    "        'Decision Tree': DecisionTreeClassifier(),\n",
    "        'SVM': SVC(),\n",
    "        'KNN': KNeighborsClassifier()\n",
    "    }\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    for name, classifier in classifiers.items():\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        print(\n",
    "            f'{type}:> '\n",
    "            f'Classifier: {name}. '\n",
    "            f'Accuracy: {accuracy_score(y_test, y_pred)}. '\n",
    "        )\n",
    "\n",
    "\n",
    "def print_diff_classifiers(X, y, selected_features, select_method: str) -> None:\n",
    "    print_accuracy(X=X, y=y, type=f\"Before {select_method}\")\n",
    "    X_selected = X[:, selected_features]\n",
    "    print_accuracy(X=X_selected, y=y, type=f\"After {select_method}\")"
   ],
   "id": "e7d99541de6dce89",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Filter method: >",
   "id": "7290da6225d9605b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:33:08.862112Z",
     "start_time": "2024-09-13T08:33:08.857740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calculate_pearson_correlation(X: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "    n_features = X.shape[1]\n",
    "    feature_correlations = np.zeros(n_features)\n",
    "    for feature_idx in range(n_features):\n",
    "        feature_values = X[:, feature_idx]\n",
    "        corr, _ = pearsonr(feature_values, y)\n",
    "        feature_correlations[feature_idx] = corr\n",
    "    return feature_correlations\n",
    "\n",
    "\n",
    "def filter_top_features_by_pearson(X, y, top_n=30) -> np.ndarray:\n",
    "    feature_correlations = calculate_pearson_correlation(X, y)\n",
    "    top_features_idx = np.argsort(np.abs(feature_correlations))[-top_n:]\n",
    "    return top_features_idx"
   ],
   "id": "2bd5ab8665201917",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:33:13.668689Z",
     "start_time": "2024-09-13T08:33:09.015765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "selected_features_idx = filter_top_features_by_pearson(frequency_matrix, y)\n",
    "selected_feature_pearson = np.array(unique_words)[selected_features_idx]\n",
    "print(\"Best features by filter Pearson correlation:\", selected_feature_pearson.tolist())"
   ],
   "id": "1b76e881d6e12826",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T02:15:06.074765Z",
     "start_time": "2024-09-13T02:14:39.185405Z"
    }
   },
   "cell_type": "code",
   "source": "print_diff_classifiers(frequency_matrix, y, selected_features_idx, select_method=\"FilterPearsonCorrelation\")",
   "id": "5ca6a8d459f2965e",
   "execution_count": 93,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "662d9385fa77e16f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Wrapper method:>",
   "id": "f287d88ffc74a7b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:44:36.416661Z",
     "start_time": "2024-09-13T08:44:36.412171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check\n",
    "class CustomRFE:\n",
    "    def __init__(self, n_features_to_select: int = 30, step: int = 1) -> None:\n",
    "        self.max_features: int = n_features_to_select\n",
    "        self.step: int = step\n",
    "        self.n_features_: tp.Optional[int] = None\n",
    "        self.support_: np.ndarray = self._init_support_()\n",
    "        self.rank_: np.ndarray = self._init_rank_()\n",
    "        self.estimator_: DecisionTreeClassifier = DecisionTreeClassifier()\n",
    "\n",
    "    def _init_rank_(self) -> np.ndarray:\n",
    "        return np.ones(self.n_features_, dtype=int)\n",
    "\n",
    "    def _init_support_(self) -> np.ndarray:\n",
    "        return np.ones(self.n_features_, dtype=bool)\n",
    "\n",
    "    def fit(self, X, y) -> np.ndarray:\n",
    "        self.n_features_ = X.shape[1]\n",
    "        self.support_ = self._init_support_()\n",
    "        self.rank_ = self._init_rank_()\n",
    "\n",
    "        while np.sum(self.support_) > self.max_features:\n",
    "            self.estimator_.fit(X[:, self.support_], y)\n",
    "            least_important = np.argsort(self.estimator_.feature_importances_)[:self.step]\n",
    "            self._upd_features(least_important)\n",
    "\n",
    "        self.rank_[self.support_] = 1\n",
    "        return np.where(self.support_)[0]\n",
    "\n",
    "    def _upd_features(self, least_important: np.ndarray) -> None:\n",
    "        for idx in least_important:\n",
    "            if idx < len(self.support_[np.where(self.support_)[0]]):\n",
    "                self._upd_support_(idx)\n",
    "                self._upd_rank_(idx)\n",
    "\n",
    "    def _upd_rank_(self, idx: int) -> None:\n",
    "        self.rank_[np.where(self.rank_)[0][idx]] = np.sum(self.rank_) + 1\n",
    "\n",
    "    def _upd_support_(self, idx: int) -> None:\n",
    "        self.support_[np.where(self.support_)[0][idx]] = False\n"
   ],
   "id": "544c7689f711b92c",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:44:37.054100Z",
     "start_time": "2024-09-13T08:44:37.051183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "frequency_matrix = frequency_matrix[:100, :]\n",
    "y = y[:100]"
   ],
   "id": "d4c1eb6197f1fc86",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:47:09.363448Z",
     "start_time": "2024-09-13T08:46:45.400171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rfe = CustomRFE(n_features_to_select=30)\n",
    "rfe.fit(frequency_matrix, y)\n",
    "rfe.rank_"
   ],
   "id": "25b29bcc6b665913",
   "execution_count": 28,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:47:15.051061Z",
     "start_time": "2024-09-13T08:47:15.044512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "important_features = np.array(unique_words)[rfe.support_]\n",
    "print(\"Best features by wrapper CustomRFE:\", important_features.tolist())"
   ],
   "id": "11ec2f039efa3d4b",
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Embedded method:>",
   "id": "e57941900e3fd314"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T08:47:18.926483Z",
     "start_time": "2024-09-13T08:47:18.879723Z"
    }
   },
   "cell_type": "code",
   "source": "print_diff_classifiers(frequency_matrix, y, rfe.support_, select_method=\"CustomRFE\")",
   "id": "e16a9544ff20cc63",
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T01:24:58.068983Z",
     "start_time": "2024-09-13T01:24:58.053673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None) -> None:\n",
    "        self.feature: tp.Optional[int] = feature\n",
    "        self.threshold: tp.Optional[float] = threshold\n",
    "        self.left: tp.Optional[Node] = left\n",
    "        self.right: tp.Optional[Node] = right\n",
    "        self.value: tp.Optional[np.signedinteger] = value\n",
    "\n",
    "    def is_leaf(self) -> bool:\n",
    "        return self.value is not None\n",
    "\n",
    "\n",
    "class CustomDecisionTree:\n",
    "    def __init__(\n",
    "            self,\n",
    "            max_depth: tp.Optional[int] = None,\n",
    "            min_samples_split: int = 2,\n",
    "            min_samples_leaf: int = 1,\n",
    "            max_features: tp.Optional[int] = None\n",
    "    ) -> None:\n",
    "        self.max_depth: tp.Optional[int] = max_depth\n",
    "        self.min_samples_to_split: int = min_samples_split\n",
    "        self.min_samples_leaf: int = min_samples_leaf\n",
    "        self.max_features: tp.Optional[int] = max_features\n",
    "        self.tree: tp.Optional[Node] = None\n",
    "        self.feature_indices: tp.Optional[np.ndarray] = None\n",
    "        self.feature_gains: tp.Optional[np.ndarray] = None\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        n_features = X.shape[1]\n",
    "        y = np.asarray(y)\n",
    "        self._init_features(n_features)\n",
    "        self.tree = self._build_tree(X, y)\n",
    "        self._update_features(n_features)\n",
    "\n",
    "    def _init_features(self, n_features: int) -> None:\n",
    "        self.feature_gains = np.zeros(n_features)\n",
    "\n",
    "    def _build_tree(self, X: np.ndarray, y: np.ndarray, depth: int = 0) -> Node:\n",
    "        n_samples, n_features = X.shape\n",
    "        self.n_classes = len(np.unique(y))\n",
    "        if self.max_depth and depth >= self.max_depth \\\n",
    "                or self.n_classes == 1 \\\n",
    "                or n_samples < self.min_samples_to_split:\n",
    "            leaf_value: np.signedinteger = self._most_common_label(y)\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        rand_features = np.random.choice(n_features, n_features, replace=False)\n",
    "        best_feature, best_threshold = self._best_criteria(X, y, rand_features)\n",
    "        left_idxs, right_idxs = self._split(X[:, best_feature], best_threshold)\n",
    "\n",
    "        if (len(left_idxs) < self.min_samples_leaf\n",
    "                or len(right_idxs) < self.min_samples_leaf):\n",
    "            leaf_value: np.signedinteger = self._most_common_label(y)\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        left = self._build_tree(X[left_idxs, :], y[left_idxs], depth + 1)\n",
    "        right = self._build_tree(X[right_idxs, :], y[right_idxs], depth + 1)\n",
    "        return Node(feature=best_feature, threshold=best_threshold, left=left, right=right)\n",
    "\n",
    "    def _update_features(self, n_features: int) -> None:\n",
    "        if self.max_features is not None:\n",
    "            top_feature_indices = np.argsort(self.feature_gains)[-self.max_features:]\n",
    "            self.feature_indices = np.sort(top_feature_indices)\n",
    "        else:\n",
    "            self.feature_indices = np.arange(n_features)\n",
    "\n",
    "    def _best_criteria(self, X: np.ndarray, y: np.ndarray, features: np.ndarray) -> tuple[int, float]:\n",
    "        best_gain = -1\n",
    "        best_feature, best_threshold = None, None\n",
    "        for feature in features:\n",
    "            X_column_by_feature = X[:, feature]\n",
    "            thresholds = np.unique(X_column_by_feature)\n",
    "            for threshold in thresholds:\n",
    "                gain = self._information_gain(y, X_column_by_feature=X_column_by_feature, split_thresh=threshold)\n",
    "                if gain > best_gain:\n",
    "                    self.feature_gains[feature] += gain\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def _information_gain(self, y, X_column_by_feature: np.ndarray, split_thresh: float) -> float:\n",
    "        parent_entropy = self._calc_entropy(y)\n",
    "        left_idxs, right_idxs = self._split(X_column_by_feature, split_thresh)\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return -1\n",
    "        n_total, n_left, n_right = len(y), len(left_idxs), len(right_idxs)\n",
    "        entropy_left, entropy_right = self._calc_entropy(y[left_idxs]), self._calc_entropy(y[right_idxs])\n",
    "        k_left, k_right = n_left / n_total, n_right / n_total\n",
    "        child_entropy = k_left * entropy_left + k_right * entropy_right\n",
    "        ig = parent_entropy - child_entropy\n",
    "        return ig\n",
    "\n",
    "    @staticmethod\n",
    "    def _split(X_column_by_feature: np.ndarray, split_thresh: float) -> tuple[np.ndarray, np.ndarray]:\n",
    "        left_idxs = np.argwhere(X_column_by_feature <= split_thresh).flatten()\n",
    "        right_idxs = np.argwhere(X_column_by_feature > split_thresh).flatten()\n",
    "        return left_idxs, right_idxs\n",
    "\n",
    "    @staticmethod\n",
    "    def _calc_entropy(y: np.ndarray) -> float:\n",
    "        p_lst = np.bincount(y) / len(y)\n",
    "        return -np.sum([p * np.log2(p) for p in p_lst if p > 0])\n",
    "\n",
    "    @staticmethod\n",
    "    def _most_common_label(y: np.ndarray) -> np.signedinteger:\n",
    "        return np.bincount(y).argmax()\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        return np.array([self._traverse_tree(x, self.tree) for x in X])\n",
    "\n",
    "    def _traverse_tree(self, x, node) -> np.signedinteger:\n",
    "        if node.is_leaf():\n",
    "            return node.value\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        return self._traverse_tree(x, node.right)\n"
   ],
   "id": "a98301e4bd3142fc",
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T01:25:12.833269Z",
     "start_time": "2024-09-13T01:24:59.554533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dt = CustomDecisionTree(\n",
    "    max_depth=5,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=3,\n",
    "    max_features=30\n",
    ")\n",
    "dt.fit(frequency_matrix, y)\n",
    "selected_feature_indices = dt.feature_indices\n",
    "selected_features = np.array(unique_words)[selected_feature_indices]\n",
    "print(\"Best features by embedded CustomDecisionTreeClassifier:\", selected_features.tolist())"
   ],
   "id": "c3343a311f519771",
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T01:27:02.145595Z",
     "start_time": "2024-09-13T01:26:34.635741Z"
    }
   },
   "cell_type": "code",
   "source": "print_diff_classifiers(frequency_matrix, y, selected_feature_indices, select_method=\"CustomDecisionTreeClassifier\")",
   "id": "fd328d372372a827",
   "execution_count": 31,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "a2e9190a70da894f",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
