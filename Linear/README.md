# Лабораторная работа: **Линейные методы**

## Набор данных

1. Выберите любой набор данных для задачи **бинарной классификации**.
   - Желательно использовать набор данных с курса **Анализа данных**.
   - Если исходный набор данных не для бинарной классификации, объедините несколько классов.
   - Примеры данных: [Kaggle Datasets](https://www.kaggle.com/datasets) или [UCI Repository](https://archive.ics.uci.edu/ml/index.php).

2. **Преобразуйте данные в числовой вид** и нормализуйте их.

3. Разделите данные на **тренировочную** и **тестовую** части.

4. Выберите целевую функцию ошибки или качества, например, **логистическую потерю** или **accuracy**.

---

## Алгоритмы

### 1. Линейная регрессия
- **Реализуйте алгоритм линейной регрессии** в матричном виде с использованием **гребневой регуляризации** (Ridge).
- Преобразуйте линейную регрессию в алгоритм **линейной классификации** путём замены целевого признака на ±1.
  - Полезные материалы: [Ridge Regression](https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression).

### 2. Линейная классификация на основе градиентного спуска
- **Реализуйте алгоритм линейной классификации** с использованием **градиентного спуска**.
- Алгоритм должен поддерживать:
  - **Не менее трёх эмпирических рисков** (например, логистическая потеря, перцептрон, хинг-лосс).
  - **Elastic Net** регуляризацию.
  - Настраиваемую **скорость градиентного спуска**.

### 3. Метод опорных векторов (SVM)
- **Реализуйте метод опорных векторов** с использованием:
  - **SMO** или градиентного спуска с восстановлением условий.
  - Алгоритм должен поддерживать **не менее трёх различных ядер**, таких как:
    - Линейное.
    - Полиномиальное.
    - Радиальное (RBF).

  - Полезные материалы: [SVM](https://scikit-learn.org/stable/modules/svm.html).

---

## Задачи

### 1. Выбор числа итераций
- Подберите число итераций для **линейной классификации** и **метода опорных векторов**, чтобы оба алгоритма выполняли примерно **асимптотически равное количество операций**.

### 2. Оптимизация гиперпараметров
- **Найдите лучшие гиперпараметры** для каждого алгоритма:
  - Линейная регрессия.
  - Линейная классификация.
  - Метод опорных векторов (SVM).

### 3. Построение кривых обучения
- Постройте **кривую обучения** с **сглаженным эмпирическим риском** на тренировочном множестве для:
  - Линейной классификации.
  - Метод опорных векторов.

- Постройте **кривую обучения** с целевой функцией ошибки или качества на **тестовом множестве** для тех же алгоритмов.
  - Не обязательно замерять целевую функцию на каждой итерации, если их много.

### 4. Сравнение с линейной регрессией
- Отметьте на графике значение целевой функции на тестовом множестве для **линейной регрессии**. Например, с помощью горизонтальной линии.

### 5. Библиотечные реализации
- **Повторите настройку гиперпараметров и тестирование** с использованием библиотечных реализаций:
  - [Linear Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html).
  - [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).
  - [SVM](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html).

- Постройте результаты на тех же графиках, что и для ваших реализаций.
- Сравните:
  - Полученные линейные уравнения для линейной регрессии и классификации.
  - **Коэффициенты опорных векторов** для вашего SVM и библиотечной реализации.

---

## Дополнительные материалы

- [Градиентный спуск](https://en.wikipedia.org/wiki/Gradient_descent).
- [Elastic Net Regularization](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html).
